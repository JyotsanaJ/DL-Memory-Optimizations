{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDdZuzE1BcMa"
      },
      "source": [
        "## Ways to optimize memory footprint and improve performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXfkot1SBcMc",
        "outputId": "2d9e11b8-0f67-4aec-b83a-e49ad512544b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -q transformers datasets accelerate nvidia-ml-py3 bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ktYFKIueBcMd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "seq_len, dataset_size = 512, 512\n",
        "dummy_data = {\n",
        "    \"input_ids\": np.random.randint(100, 30000, (dataset_size, seq_len)),\n",
        "    \"labels\": np.random.randint(0, 1, (dataset_size)),\n",
        "}\n",
        "ds = Dataset.from_dict(dummy_data)\n",
        "ds.set_format(\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2hMopN9BcMe",
        "outputId": "44bb9d34-4d62-4659-de56-69bb4dce86f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(512, 2)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vhzEnpv1BcMe"
      },
      "outputs": [],
      "source": [
        "from pynvml import *\n",
        "\n",
        "\n",
        "def print_gpu_utilization():\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
        "\n",
        "\n",
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yLaCfIzBcMe",
        "outputId": "10236416-23c6-4839-88d7-54acc6652769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU memory occupied: 258 MB.\n"
          ]
        }
      ],
      "source": [
        "print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-oqEb4xBcMe",
        "outputId": "3a0ef403-70f2-419b-d4a5-fb105c14543b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU memory occupied: 362 MB.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.ones((1, 1)).to(\"cuda\")\n",
        "print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262,
          "referenced_widgets": [
            "dd95000870bb4c9793616ffe3ac22d7a",
            "2cff1c3b5211460fb05758d9ef154a4f",
            "e32b69e56c704d9cbcb5f4a3bcacdbff",
            "a1e851eb00f24efa8c5f3f9ca65770f2",
            "f92bb2515d81445abedf886aa4bfc24e",
            "ec2381c196c742d9b032d6ca13948264",
            "a932847ba78e4e539222cd93d2aa60ae",
            "a41af8fac6fd462da831b949e7e9a10d",
            "fc42a119f5084350b00c7ea6f7a36e04",
            "e7a19266c09f487ca2d2d1f2afe4eb63",
            "82447ebc04904ce79a130362c862d349",
            "4bc34005aa884929826db8c109fdb5ad",
            "87446414d8a24ead8144327c1ecdd8b2",
            "2c1dd6eb205c403a899afd90fe2d7436",
            "893df19d7ab147d2b73cc6337e35d586",
            "bf07c3aa7366472c9c441598d1f32a91",
            "b9096714209d4dc59bea20aa9227a640",
            "494976a1ca1646c4adaa2cd2c90a6e7b",
            "a52f650a7a2b4df3b0876b578ceeaa7c",
            "417f39c5c74c41ad9ccd89e8c7b66945",
            "be2f1c157ca04f9681c9d837ed3646ee",
            "f6b5fce0638a4db983942f6972837d31"
          ]
        },
        "id": "br9h50gvCF_s",
        "outputId": "13252fbe-c561-4918-8f03-6bbf48f3a221"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-large-uncased\").to(\"cuda\")\n",
        "print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MQrynjuZCTZB"
      },
      "outputs": [],
      "source": [
        "default_args = {\n",
        "    \"output_dir\": \"tmp\",\n",
        "    \"evaluation_strategy\": \"steps\",\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"log_level\": \"error\",\n",
        "    \"report_to\": \"none\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik8q2yPbCzWV",
        "outputId": "3f9def74-0ccb-4053-b43c-dbb2a0746a32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 185.4077, 'train_samples_per_second': 2.761, 'train_steps_per_second': 0.69, 'train_loss': 0.023786330595612526, 'epoch': 1.0}\n",
            "Time: 185.41\n",
            "Samples/second: 2.76\n",
            "GPU memory occupied: 11538 MB.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer, logging\n",
        "\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "training_args = TrainingArguments(per_device_train_batch_size=4, **default_args)\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
        "result = trainer.train()\n",
        "print_summary(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lk6EVb1D12_"
      },
      "source": [
        "A simple trick to effectively train larger batch size is gradient accumulation. We are not limited by GPU size but only our requirements.\n",
        "## Gradient Accumulation\n",
        "\n",
        "* instead of calculating the gradients for the whole batch at once to do it in smaller steps.\n",
        "* The way we do that is to calculate the gradients iteratively in smaller batches by doing a forward and backward pass through the model and accumulating the gradients in the process.\n",
        "* When enough gradients are accumulated we run the model’s optimization step.\n",
        "* We can see that the memory footprint was dramatically reduced at the cost of being only slightly slower than the vanilla run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCIaDJotDCqU",
        "outputId": "c684603f-fe53-4c3c-ffc7-0534ff9da10a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 204.5286, 'train_samples_per_second': 2.503, 'train_steps_per_second': 0.626, 'train_loss': 0.009834381751716137, 'epoch': 1.0}\n",
            "Time: 204.53\n",
            "Samples/second: 2.50\n",
            "GPU memory occupied: 7222 MB.\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(per_device_train_batch_size=1, gradient_accumulation_steps=4, **default_args)\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
        "result = trainer.train()\n",
        "print_summary(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeUxQXUNEYJB",
        "outputId": "c64fb316-4a35-4e63-c05f-1be6789596f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 172.3912, 'train_samples_per_second': 2.97, 'train_steps_per_second': 0.046, 'train_loss': 1.492358569521457e-05, 'epoch': 1.0}\n",
            "Time: 172.39\n",
            "Samples/second: 2.97\n",
            "GPU memory occupied: 12362 MB.\n"
          ]
        }
      ],
      "source": [
        "## If we want to use GPU to its limit we can increase the batch_size and also enable gradient checkpointing to 16\n",
        "\n",
        "training_args = TrainingArguments(per_device_train_batch_size=4,\n",
        "                                  gradient_accumulation_steps=16,\n",
        "                                  **default_args\n",
        "                                  )\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
        "result = trainer.train()\n",
        "print_summary(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD5bCwvhFEj4"
      },
      "source": [
        "## Gradient Checkpointing\n",
        "\n",
        "* In order to compute the gradients during the backward pass all activations from the forward pass are normally saved. This can create a big memory overhead.\n",
        "* We can see that this saved some more memory but at the same time training became a bit slower. \n",
        "* A general rule of thumb is that gradient checkpointing slows down training by about 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2A0kRixK5aZ",
        "outputId": "f2b35783-9b3a-49d1-8fff-b1639e4b95e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 270.1824, 'train_samples_per_second': 1.895, 'train_steps_per_second': 0.474, 'train_loss': 3.655438973737546e-08, 'epoch': 1.0}\n",
            "Time: 270.18\n",
            "Samples/second: 1.90\n",
            "GPU memory occupied: 6842 MB.\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=1, gradient_accumulation_steps=4, gradient_checkpointing=True, **default_args\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
        "result = trainer.train()\n",
        "print_summary(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP-ttUJ7LJWN"
      },
      "source": [
        "## FP16 Training (Mixed precision Training)\n",
        "* The main advantage comes from saving the activations in half (16-bit) precision.\n",
        "* Gradients calculated in half but converted back to float32.\n",
        "* Just fp16 has 2 copies of model saved so hardly saves any memory.\n",
        "* Also there is some overhead extra computation so not that great on time. \n",
        "* But add it with other methods and it performs good."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-0GSn8OK7jk",
        "outputId": "838373d4-60a7-445c-a982-048f06fb48c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 92.4081, 'train_samples_per_second': 5.541, 'train_steps_per_second': 1.385, 'train_loss': 0.0, 'epoch': 1.0}\n",
            "Time: 92.41\n",
            "Samples/second: 5.54\n",
            "GPU memory occupied: 6826 MB.\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(per_device_train_batch_size=4, fp16=True, **default_args)\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
        "result = trainer.train()\n",
        "print_summary(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loNjhBxHP6QL",
        "outputId": "99f2afab-97f4-4bb6-ae83-29eb431621a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 116.9351, 'train_samples_per_second': 4.378, 'train_steps_per_second': 1.095, 'train_loss': 0.0, 'epoch': 1.0}\n",
            "Time: 116.94\n",
            "Samples/second: 4.38\n",
            "GPU memory occupied: 9416 MB.\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    **default_args,\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
        "result = trainer.train()\n",
        "print_summary(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNi8lLp3QXBZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTU0PUl4QYWB"
      },
      "source": [
        "## Optimizers\n",
        "* Use optimizers like adaFactor which saved aggregated gradient and not rolling gradient and save some space.\n",
        "* With everything we see a 3x memory reduction.\n",
        "* One downside of Adafactor is that in some instances convergence can be slower than Adam’s.\n",
        "* But as Adafactor is slow we can use 8-bit Adam as an alternate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWfbMWJSQ8TR",
        "outputId": "10380f51-65c0-4e14-ceae-7e97f70e816d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 130.4237, 'train_samples_per_second': 3.926, 'train_steps_per_second': 0.981, 'train_loss': 0.0, 'epoch': 1.0}\n",
            "Time: 130.42\n",
            "Samples/second: 3.93\n",
            "GPU memory occupied: 6460 MB.\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    optim=\"adafactor\",\n",
        "    **default_args,\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
        "result = trainer.train()\n",
        "print_summary(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XhV8-3oRYE-"
      },
      "source": [
        "## 8-bit Adam\n",
        "* It stores the rolling average but quantizes it i.e less precision and dequantizes it only for the optimization\n",
        "* install the **bitsandbytes** library that implements the 8-bit Adam optimizer.\n",
        "* Group parameters into group that weight decay and that doesn't.\n",
        "* Usually, biases and layer norm parameters are not weight decayed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Anh1qZhNStW-",
        "outputId": "a235ae48-7abb-4beb-d45a-644827e7f479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "149 ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.12.attention.self.query.weight', 'bert.encoder.layer.12.attention.self.key.weight', 'bert.encoder.layer.12.attention.self.value.weight', 'bert.encoder.layer.12.attention.output.dense.weight', 'bert.encoder.layer.12.intermediate.dense.weight', 'bert.encoder.layer.12.output.dense.weight', 'bert.encoder.layer.13.attention.self.query.weight', 'bert.encoder.layer.13.attention.self.key.weight', 'bert.encoder.layer.13.attention.self.value.weight', 'bert.encoder.layer.13.attention.output.dense.weight', 'bert.encoder.layer.13.intermediate.dense.weight', 'bert.encoder.layer.13.output.dense.weight', 'bert.encoder.layer.14.attention.self.query.weight', 'bert.encoder.layer.14.attention.self.key.weight', 'bert.encoder.layer.14.attention.self.value.weight', 'bert.encoder.layer.14.attention.output.dense.weight', 'bert.encoder.layer.14.intermediate.dense.weight', 'bert.encoder.layer.14.output.dense.weight', 'bert.encoder.layer.15.attention.self.query.weight', 'bert.encoder.layer.15.attention.self.key.weight', 'bert.encoder.layer.15.attention.self.value.weight', 'bert.encoder.layer.15.attention.output.dense.weight', 'bert.encoder.layer.15.intermediate.dense.weight', 'bert.encoder.layer.15.output.dense.weight', 'bert.encoder.layer.16.attention.self.query.weight', 'bert.encoder.layer.16.attention.self.key.weight', 'bert.encoder.layer.16.attention.self.value.weight', 'bert.encoder.layer.16.attention.output.dense.weight', 'bert.encoder.layer.16.intermediate.dense.weight', 'bert.encoder.layer.16.output.dense.weight', 'bert.encoder.layer.17.attention.self.query.weight', 'bert.encoder.layer.17.attention.self.key.weight', 'bert.encoder.layer.17.attention.self.value.weight', 'bert.encoder.layer.17.attention.output.dense.weight', 'bert.encoder.layer.17.intermediate.dense.weight', 'bert.encoder.layer.17.output.dense.weight', 'bert.encoder.layer.18.attention.self.query.weight', 'bert.encoder.layer.18.attention.self.key.weight', 'bert.encoder.layer.18.attention.self.value.weight', 'bert.encoder.layer.18.attention.output.dense.weight', 'bert.encoder.layer.18.intermediate.dense.weight', 'bert.encoder.layer.18.output.dense.weight', 'bert.encoder.layer.19.attention.self.query.weight', 'bert.encoder.layer.19.attention.self.key.weight', 'bert.encoder.layer.19.attention.self.value.weight', 'bert.encoder.layer.19.attention.output.dense.weight', 'bert.encoder.layer.19.intermediate.dense.weight', 'bert.encoder.layer.19.output.dense.weight', 'bert.encoder.layer.20.attention.self.query.weight', 'bert.encoder.layer.20.attention.self.key.weight', 'bert.encoder.layer.20.attention.self.value.weight', 'bert.encoder.layer.20.attention.output.dense.weight', 'bert.encoder.layer.20.intermediate.dense.weight', 'bert.encoder.layer.20.output.dense.weight', 'bert.encoder.layer.21.attention.self.query.weight', 'bert.encoder.layer.21.attention.self.key.weight', 'bert.encoder.layer.21.attention.self.value.weight', 'bert.encoder.layer.21.attention.output.dense.weight', 'bert.encoder.layer.21.intermediate.dense.weight', 'bert.encoder.layer.21.output.dense.weight', 'bert.encoder.layer.22.attention.self.query.weight', 'bert.encoder.layer.22.attention.self.key.weight', 'bert.encoder.layer.22.attention.self.value.weight', 'bert.encoder.layer.22.attention.output.dense.weight', 'bert.encoder.layer.22.intermediate.dense.weight', 'bert.encoder.layer.22.output.dense.weight', 'bert.encoder.layer.23.attention.self.query.weight', 'bert.encoder.layer.23.attention.self.key.weight', 'bert.encoder.layer.23.attention.self.value.weight', 'bert.encoder.layer.23.attention.output.dense.weight', 'bert.encoder.layer.23.intermediate.dense.weight', 'bert.encoder.layer.23.output.dense.weight', 'bert.pooler.dense.weight', 'classifier.weight']\n"
          ]
        }
      ],
      "source": [
        "import bitsandbytes as bnb\n",
        "from torch import nn\n",
        "from transformers.trainer_pt_utils import get_parameter_names\n",
        "\n",
        "training_args = TrainingArguments(per_device_train_batch_size=4, **default_args)\n",
        "\n",
        "decay_parameters = get_parameter_names(model, [nn.LayerNorm])\n",
        "decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n",
        "print(len(decay_parameters), decay_parameters)\n",
        "\n",
        "## Add weight_decay to all parameters which can decay. Other params will have decay 0.0\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if n in decay_parameters],\n",
        "        \"weight_decay\": training_args.weight_decay,\n",
        "    },\n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if n not in decay_parameters],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "]\n",
        "\n",
        "## Copy Beta values from training args\n",
        "optimizer_kwargs = {\n",
        "    \"betas\": (training_args.adam_beta1, training_args.adam_beta2),\n",
        "    \"eps\": training_args.adam_epsilon,\n",
        "}\n",
        "\n",
        "## Copy LR values from Training Args\n",
        "optimizer_kwargs[\"lr\"] = training_args.learning_rate\n",
        "adam_bnb_optim = bnb.optim.Adam8bit(\n",
        "    optimizer_grouped_parameters,\n",
        "    betas=(training_args.adam_beta1, training_args.adam_beta2),\n",
        "    eps=training_args.adam_epsilon,\n",
        "    lr=training_args.learning_rate,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dcKginFUXkA",
        "outputId": "0f62d3de-9ebf-45f1-b7ec-3cca1ae25d76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 112.4754, 'train_samples_per_second': 4.552, 'train_steps_per_second': 1.138, 'train_loss': 0.0, 'epoch': 1.0}\n",
            "Time: 112.48\n",
            "Samples/second: 4.55\n",
            "GPU memory occupied: 4426 MB.\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    **default_args,\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=ds, optimizers=(adam_bnb_optim, None))\n",
        "result = trainer.train()\n",
        "print_summary(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppFqz3jGUfOO"
      },
      "source": [
        "## Accelerate\n",
        "*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8mbgnXd0UvZb"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    **default_args,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84TOkS2tS7cl",
        "outputId": "8cf3f9a5-ff93-4655-81b3-308460cb5e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU memory occupied: 4612 MB.\n"
          ]
        }
      ],
      "source": [
        "from accelerate import Accelerator\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "dataloader = DataLoader(ds, batch_size=training_args.per_device_train_batch_size)\n",
        "\n",
        "if training_args.gradient_checkpointing:\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "## Define accelerator to use mixed precision\n",
        "accelerator = Accelerator(mixed_precision=\"fp16\")\n",
        "model, optimizer, dataloader = accelerator.prepare(model, adam_bnb_optim, dataloader)\n",
        "\n",
        "model.train()\n",
        "for step, batch in enumerate(dataloader, start=1):\n",
        "    loss = model(**batch).loss\n",
        "    loss = loss / training_args.gradient_accumulation_steps\n",
        "    accelerator.backward(loss)\n",
        "    if step % training_args.gradient_accumulation_steps == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "print_gpu_utilization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi3nRYmVV41A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c1dd6eb205c403a899afd90fe2d7436": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a52f650a7a2b4df3b0876b578ceeaa7c",
            "max": 1344951957,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_417f39c5c74c41ad9ccd89e8c7b66945",
            "value": 1344951957
          }
        },
        "2cff1c3b5211460fb05758d9ef154a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec2381c196c742d9b032d6ca13948264",
            "placeholder": "​",
            "style": "IPY_MODEL_a932847ba78e4e539222cd93d2aa60ae",
            "value": "config.json: 100%"
          }
        },
        "417f39c5c74c41ad9ccd89e8c7b66945": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "494976a1ca1646c4adaa2cd2c90a6e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bc34005aa884929826db8c109fdb5ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87446414d8a24ead8144327c1ecdd8b2",
              "IPY_MODEL_2c1dd6eb205c403a899afd90fe2d7436",
              "IPY_MODEL_893df19d7ab147d2b73cc6337e35d586"
            ],
            "layout": "IPY_MODEL_bf07c3aa7366472c9c441598d1f32a91"
          }
        },
        "82447ebc04904ce79a130362c862d349": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87446414d8a24ead8144327c1ecdd8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9096714209d4dc59bea20aa9227a640",
            "placeholder": "​",
            "style": "IPY_MODEL_494976a1ca1646c4adaa2cd2c90a6e7b",
            "value": "model.safetensors: 100%"
          }
        },
        "893df19d7ab147d2b73cc6337e35d586": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be2f1c157ca04f9681c9d837ed3646ee",
            "placeholder": "​",
            "style": "IPY_MODEL_f6b5fce0638a4db983942f6972837d31",
            "value": " 1.34G/1.34G [00:11&lt;00:00, 196MB/s]"
          }
        },
        "a1e851eb00f24efa8c5f3f9ca65770f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a19266c09f487ca2d2d1f2afe4eb63",
            "placeholder": "​",
            "style": "IPY_MODEL_82447ebc04904ce79a130362c862d349",
            "value": " 571/571 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "a41af8fac6fd462da831b949e7e9a10d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52f650a7a2b4df3b0876b578ceeaa7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a932847ba78e4e539222cd93d2aa60ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9096714209d4dc59bea20aa9227a640": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be2f1c157ca04f9681c9d837ed3646ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf07c3aa7366472c9c441598d1f32a91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd95000870bb4c9793616ffe3ac22d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cff1c3b5211460fb05758d9ef154a4f",
              "IPY_MODEL_e32b69e56c704d9cbcb5f4a3bcacdbff",
              "IPY_MODEL_a1e851eb00f24efa8c5f3f9ca65770f2"
            ],
            "layout": "IPY_MODEL_f92bb2515d81445abedf886aa4bfc24e"
          }
        },
        "e32b69e56c704d9cbcb5f4a3bcacdbff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a41af8fac6fd462da831b949e7e9a10d",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc42a119f5084350b00c7ea6f7a36e04",
            "value": 571
          }
        },
        "e7a19266c09f487ca2d2d1f2afe4eb63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec2381c196c742d9b032d6ca13948264": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6b5fce0638a4db983942f6972837d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f92bb2515d81445abedf886aa4bfc24e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc42a119f5084350b00c7ea6f7a36e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
