{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dJnDNC8_5VL"
      },
      "source": [
        "## Mixed precision Training\n",
        "\n",
        "* Ordinarily, “automatic mixed precision training” uses torch.autocast and torch.cuda.amp.GradScaler together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e0rrjWi8_5VN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.cuda.amp import GradScaler, autocast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "tGhytMip_5VO"
      },
      "outputs": [],
      "source": [
        "# Define your model architecture\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(784, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logit = self.linear_relu_stack(x)\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBKehQvw_5VO",
        "outputId": "6e3c185d-adef-40b7-c229-50dc5bfab527"
      },
      "outputs": [],
      "source": [
        "# Load your dataset (for example, MNIST)\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CrsGwHI_5VO",
        "outputId": "075908ea-39e8-4959-b630-475401475d7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5,), std=(0.5,))\n",
              "           )"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-moJPccX_5VO",
        "outputId": "73283b98-50a0-4baa-e38d-216af7333be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "# Initialize your model, optimizer, and scaler\n",
        "model = MyModel().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaElmVKk_5VP",
        "outputId": "75587be0-6962-47d8-c453-51e8ae57b5e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7ad7c8fa4880>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig2hSRC0_5VP"
      },
      "source": [
        "## torch.autocast\n",
        "\n",
        "* serve as context managers that allow regions of your script to run in mixed precision.\n",
        "* CUDA ops run in a dtype chosen by autocast to improve performance while maintaining accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnIyRqRO_5VP",
        "outputId": "25f34cfc-c51b-4cf8-ae79-07cf645c4843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [1/938], Loss: 2.29779052734375\n",
            "Epoch [1/5], Step [101/938], Loss: 0.6141790747642517\n",
            "Epoch [1/5], Step [201/938], Loss: 0.4575044512748718\n",
            "Epoch [1/5], Step [301/938], Loss: 0.1804271787405014\n",
            "Epoch [1/5], Step [401/938], Loss: 0.2871459722518921\n",
            "Epoch [1/5], Step [501/938], Loss: 0.39320069551467896\n",
            "Epoch [1/5], Step [601/938], Loss: 0.17561626434326172\n",
            "Epoch [1/5], Step [701/938], Loss: 0.2798739969730377\n",
            "Epoch [1/5], Step [801/938], Loss: 0.2054775357246399\n",
            "Epoch [1/5], Step [901/938], Loss: 0.20905619859695435\n",
            "Epoch [2/5], Step [1/938], Loss: 0.0883687436580658\n",
            "Epoch [2/5], Step [101/938], Loss: 0.3113597631454468\n",
            "Epoch [2/5], Step [201/938], Loss: 0.08547207713127136\n",
            "Epoch [2/5], Step [301/938], Loss: 0.07507798075675964\n",
            "Epoch [2/5], Step [401/938], Loss: 0.04894807189702988\n",
            "Epoch [2/5], Step [501/938], Loss: 0.19935643672943115\n",
            "Epoch [2/5], Step [601/938], Loss: 0.11764001846313477\n",
            "Epoch [2/5], Step [701/938], Loss: 0.3508676290512085\n",
            "Epoch [2/5], Step [801/938], Loss: 0.06543655693531036\n",
            "Epoch [2/5], Step [901/938], Loss: 0.08736220002174377\n",
            "Epoch [3/5], Step [1/938], Loss: 0.17784397304058075\n",
            "Epoch [3/5], Step [101/938], Loss: 0.1287233531475067\n",
            "Epoch [3/5], Step [201/938], Loss: 0.19146957993507385\n",
            "Epoch [3/5], Step [301/938], Loss: 0.08561398088932037\n",
            "Epoch [3/5], Step [401/938], Loss: 0.07981161773204803\n",
            "Epoch [3/5], Step [501/938], Loss: 0.1297098994255066\n",
            "Epoch [3/5], Step [601/938], Loss: 0.05989252030849457\n",
            "Epoch [3/5], Step [701/938], Loss: 0.14888489246368408\n",
            "Epoch [3/5], Step [801/938], Loss: 0.11661235988140106\n",
            "Epoch [3/5], Step [901/938], Loss: 0.1030692309141159\n",
            "Epoch [4/5], Step [1/938], Loss: 0.1568252444267273\n",
            "Epoch [4/5], Step [101/938], Loss: 0.04276936873793602\n",
            "Epoch [4/5], Step [201/938], Loss: 0.12193304300308228\n",
            "Epoch [4/5], Step [301/938], Loss: 0.17941372096538544\n",
            "Epoch [4/5], Step [401/938], Loss: 0.020809024572372437\n",
            "Epoch [4/5], Step [501/938], Loss: 0.13840030133724213\n",
            "Epoch [4/5], Step [601/938], Loss: 0.022777879610657692\n",
            "Epoch [4/5], Step [701/938], Loss: 0.04605431854724884\n",
            "Epoch [4/5], Step [801/938], Loss: 0.039254240691661835\n",
            "Epoch [4/5], Step [901/938], Loss: 0.09066824615001678\n",
            "Epoch [5/5], Step [1/938], Loss: 0.06360010802745819\n",
            "Epoch [5/5], Step [101/938], Loss: 0.13630226254463196\n",
            "Epoch [5/5], Step [201/938], Loss: 0.10554828494787216\n",
            "Epoch [5/5], Step [301/938], Loss: 0.0112584438174963\n",
            "Epoch [5/5], Step [401/938], Loss: 0.037021756172180176\n",
            "Epoch [5/5], Step [501/938], Loss: 0.03634655848145485\n",
            "Epoch [5/5], Step [601/938], Loss: 0.0866718739271164\n",
            "Epoch [5/5], Step [701/938], Loss: 0.020657064393162727\n",
            "Epoch [5/5], Step [801/938], Loss: 0.0422346293926239\n",
            "Epoch [5/5], Step [901/938], Loss: 0.04705566540360451\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(5):  # Example: 5 epochs\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Move data to GPU\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass with autocast for mixed precision\n",
        "        with autocast(dtype=torch.float16):\n",
        "            output = model(data)\n",
        "            assert output.dtype is torch.float16\n",
        "            loss = nn.functional.cross_entropy(output, target)\n",
        "            assert loss.dtype is torch.float32\n",
        "\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # Update model parameters\n",
        "        scaler.step(optimizer)\n",
        "\n",
        "        # Update scaler for next iteration\n",
        "        scaler.update()\n",
        "\n",
        "        # Print training progress\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{5}], Step [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item()}')\n",
        "\n",
        "print(\"Training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9IJJHrS_5VP",
        "outputId": "2f83c169-d6f1-4068-882c-5520c3e16619"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss.dtype is torch.float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeJZ3HF__5VP"
      },
      "source": [
        "## Adding GradScaler\n",
        "Gradient scaling helps prevent gradients with small magnitudes from flushing to zero (“underflowing”) when training with mixed precision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNviiMar_5VP"
      },
      "outputs": [],
      "source": [
        "# Constructs a ``scaler`` once, at the beginning of the convergence run, using default arguments.\n",
        "# The same ``GradScaler`` instance should be used for the entire convergence run.\n",
        "# If you perform multiple convergence runs in the same script, each run should use\n",
        "# a dedicated fresh ``GradScaler`` instance. ``GradScaler`` instances are lightweight.\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch in range(5): # 0 epochs, this section is for illustration only\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Move data to GPU\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(dtype=torch.float16):\n",
        "            output = model(data)\n",
        "            loss = nn.functional.cross_entropy(output, target)\n",
        "\n",
        "        # Scales loss. Calls ``backward()`` on scaled loss to create scaled gradients.\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # ``scaler.step()`` first unscales the gradients of the optimizer's assigned parameters.\n",
        "        # If these gradients do not contain ``inf``s or ``NaN``s, optimizer.step() is then called,\n",
        "        # otherwise, optimizer.step() is skipped.\n",
        "        scaler.step(optimizer)\n",
        "\n",
        "        # Updates the scale for next iteration.\n",
        "        scaler.update()\n",
        "\n",
        "        optimizer.zero_grad() # set_to_none=True here can modestly improve performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiasZkPR_5VP"
      },
      "outputs": [],
      "source": [
        "use_amp = True\n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "for epoch in range(5):\n",
        "    for input, target in zip(data, target):\n",
        "        with torch.autocast(device_type=device, dtype=torch.float16, enabled=use_amp):\n",
        "            output = model(input)\n",
        "            loss = nn.functional.cross_entropy(output, target)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "        opt.zero_grad() # set_to_none=True here can modestly improve performance\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
